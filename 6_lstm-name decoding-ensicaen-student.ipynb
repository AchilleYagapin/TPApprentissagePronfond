{"cells":[{"cell_type":"markdown","metadata":{"id":"I9dQSYDDngAQ"},"source":["# TP BLOC 5 : application des réseaux récurrents à la traduction de chaines de caractères\n","\n","**Objectif** : des prénoms, représentés sous la forme de chaines de caractères, ont été encryptés par un algorithme inconnu.\n","\n","Trois jeux de données vous ont fournis dans le dossier `./6_data_lstm_transform` (train/test set 1,2,3). Les jeux de données sont des ensembles de prénoms \"d'entrainement\" pour lesquels vous disposerez de la chaine de caractère cryptée et de la chaine de caractères décryptée. Pour chacun des jeux d'entraînement, la fonction de chiffrement est différente.\n","\n","Vous devrez apprendre un modèle à base de LSTM capable de décrypter un jeu de prénoms de test pour lequel seul la version cryptée est fournie. Pour les besoins du TP, les chaines de caractères décryptées vous sont également fournies pour le jeu de test afin que vous puissiez vérifier le bon fonctionnement de votre modèle.\n","\n","---\n","\n","\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"0mHePKhpxCTB"},"source":["### 1. récupération des données\n","\n","Les séquences de chaines de caractères sont contenus dans deux fichiers, l'un avec les données d'entrainement, l'autre avec celles de test.\n","\n","Pour chacun, deux tenseurs sont fournis : le premier contient les séquences 'source' qui sont les séquences cryptées, l'autre les séquences 'target' qui sont décryptés. \n","\n","Nous vous donnons également une fonction qui permet de transformer les séquences de chiffres en séquences de lettres, plus facile à lire pour les humains.\n","\n","Toutes les séquences ont été ramenées à 16 caractères par padding. Vous remarquerez aussi qu'il y a un caractère spécial qui marque le début de la chaine.\n","\n","En regardant les paires de séquences cryptées/décryptées, essayez de comprendre quel code est utilisé pour le cryptage.\n","\n","En quoi cela justifie-t-il l'usage de réseaux de neurones prenant en compte des données séquentielles ?"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# IMPORTS\n","\n","import torch\n","import torch.nn as nn\n","\n","import pathlib"]},{"cell_type":"markdown","metadata":{},"source":["Si vous utilisez **google colab** :"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","# !ls 'gdrive/My Drive/Colab Notebooks/formation IA niveau 3/module 7 advanced ML/Day2'"]},{"cell_type":"markdown","metadata":{},"source":["Dans tous les cas, **définir le fichier où se trouvent les données**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["cur_dir = './6_data_lstm_transformers'"]},{"cell_type":"markdown","metadata":{},"source":["**Extraction des données et visualisation**\n","\n","Description des données :\n","- Les données sont des séquences d'entier qui représentent des lettres en format ascii. La fonction `ascii2str` permet de visualiser le texte correspondant\n","- Pour chaque dataset, on extrait :\n","    - Les données source (src) qui correspondent au texte chiffré\n","    - Les données cible/target (tgt) qui correspondent au texte déchiffré que l'on cherche à prédire\n","    - `num_codes` : correspond au nombre de caractères différents qui peuvent apparaître dans les séquences "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["src_train,tgt_train, num_codes = torch.load(cur_dir+'/'+'train_set.pt', weights_only=True)\n","src_test,tgt_test, num_codes = torch.load(cur_dir+'/'+'test_set.pt', weights_only=True)\n","seq_len = tgt_train.shape[1]\n","\n","print(f\"Num codes={num_codes}\")\n","print(\"taille des tenseurs pour l'entrainement\", tgt_train.shape,src_train.shape)\n","print(\"taille des tenseurs pour le test\", tgt_test.shape,src_test.shape)\n","print(\"longueur des séquences : \",seq_len)\n","def ascii2str(x):\n","  string =  ''.join([chr(int(i)+ord('a')) if (int(i)+ord('a'))!=ord('z')+2 else '.'  for i in x])\n","  new_string = string.replace(\"{\", \"-\" )\n","  return new_string\n","\n","for i in range(20):\n","  print('source : [',ascii2str(src_train[i,:]),\"] -> target : [\",ascii2str(tgt_train[i,:]),']')\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ksWowVeUyq1N"},"source":["### 2. Construction d'un dataset pytorch\n","\n","Vous allez désormais construire un objet de type 'torch.utils.data.Dataset' dataset compatible avec les \"data loader\" (torch.utils.data.DataLoader) de pytorch. \n","\n","Les dernières instructions de la cellule (celles qui vous sont fournies) vous permettra de vérifier que ce que vous avez fait fonctionne."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1670392794220,"user":{"displayName":"Frederic Jurie","userId":"12594106507093435689"},"user_tz":-60},"id":"EdcPS1PVZxx7","outputId":"b5f774ed-1c75-4516-c997-12c18f8b8be8"},"outputs":[],"source":["\"\"\"\n","à vous d'écrire cette classe\n","\n","class CustomDataset(torch.utils.data.Dataset):\n","...\n","\"\"\"\n","\n","class CustomDataset(torch.utils.data.Dataset):\n","\tdef __init__(self):\n","\t\tpass\n","\t\t\n","\tdef __getitem__(self, idx):\n","\t\tpass\n","\tdef __len__(self):\n","\t\tpass\n","\n","trainset = CustomDataset(src_train,tgt_train)\n","testset = CustomDataset(src_test,tgt_test)\n","\n","train_loader = torch.utils.data.DataLoader(dataset=trainset, batch_size=64, shuffle=True)\n","test_loader = torch.utils.data.DataLoader(dataset=testset, batch_size=16, shuffle=True)\n","\n","for x_src, x_tgt in test_loader:\n","\tfor i in range(x_src.shape[0]):\n","\t\tprint(ascii2str(x_src[i]), '->', ascii2str(x_tgt[i]))\n","\tbreak"]},{"cell_type":"markdown","metadata":{"id":"OGpv7HwJ2_-e"},"source":["### 3. Construction du modèle à base de LSTM\n","\n","Vous construirez ensuite le modèle de LSTM qui permet de faire la traduction de chaines de *caractères*.\n","\n","Le modèle prend en entrée une chaîne de caractère chiffrée et doit prédire le texte déchiffré correspondant\n","\n","Par la suite, vous pourrez par exemple, **représenter les caractères par un embedding de taille 20**."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HCWEw79P0rbQ"},"outputs":[],"source":["\"\"\"\n","à vous d'écrire le modèle\n","\n","class mymodel(torch.nn.Module):\n","\"\"\"\n","\n","class mymodel(torch.nn.Module):\n","    def __init__(self):\n","        pass\n","\n","\n","    def forward(self, x_src):\n","        pass"]},{"cell_type":"markdown","metadata":{"id":"kvj3r_7N3bkx"},"source":["### 4. Entrainement du modèle\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\"\"\"\n","à vous d'entrainer le modèle\n","\"\"\"\n","\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f\"Using {device=}\")\n","\n","embedding_size=20\n","learning_rate = 1e-3\n","model = mymodel(num_codes=num_codes, embedding_size=32, hidden_size = 256, num_layers = 2).to(device)\n","model.training = True\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)   \n","\n","\n","NUM_EPOCH=50\n","\n","criterion = torch.nn.CrossEntropyLoss()\n","\n","def train_model(model, nb_epochs ...):\n","    \n","\tfor epoch in range(nb_epochs):\n","\t\tglobal_loss=0\n","\t\tx_prediction = ...\n","\t\tif epoch%10==0:\n","\t\t\tprint('epoch: ',epoch, 'loss: ',global_loss)\n","\t\t\tprint(\"exemple de décodage d'une donnée de train : \",ascii2str(x_tgt[0,:]),' -> ',ascii2str(torch.argmax(x_prediction,axis=2)[0]),'<fin>')\n","\t\t\tmy_file = pathlib.Path(f'./model_lstm_epoch{epoch}.pt')\n","\t\t\ttorch.save({'optimizer':optimizer.state_dict(), 'model':model.state_dict()}, my_file)"]},{"cell_type":"markdown","metadata":{"id":"iwjVPAIU8jcG"},"source":["### 5. Décodage du jeu de test\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":340,"status":"ok","timestamp":1670393076938,"user":{"displayName":"Frederic Jurie","userId":"12594106507093435689"},"user_tz":-60},"id":"BWyfCwIf7Urv","outputId":"295a3832-2b57-4172-cc16-1464841a7b31"},"outputs":[],"source":["\"\"\"\n","à vous de faire les inférences sur le jeu de test\n","\"\"\"\n","\n","def test_model(model):\n","    model.training = False\n","    with torch.no_grad():\n","        ...\n","        x_pred_decoded = ...\n","        loss_eval = ...\n","        print(\"décodage de [\", ascii2str(x_src[i]),\"] -> [\",ascii2str(x_pred_decoded[i]) ,\"] GT = \",ascii2str(x_tgt[i]), \"Loss Value=\", loss_eval)\n"]},{"cell_type":"markdown","metadata":{},"source":["### 6. Essayer avec les autres jeux de données\n","\n","Maintenant que l'on a entrainé un modèle à déchiffré des données textuelles, essayez votre modèle avec les autres jeux de données.\n","- Le modèle 1 fonctionne t'il avec les autres modèles ?\n","- Entrainez des nouveaux modèles sur les autres jeux de données et comparez les performances des modèles\n","- Des trois modèles, lequel performe le mieux ? Arrivez-vous à trouver de façon analytique quelle est la fonction de chiffrement utilisée dans les modèles 2 et 3 ?"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":0}
